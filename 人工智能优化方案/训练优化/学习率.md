# 学习率

学习率在训练过程中可以动态调整来提高模型收敛的速度，例如:

- 假设我们的前 100 epoch 将损失值下降到了 1.0 左右
- 再继续进行训练时，出现了损失值不再下降，或损失值增加的情况
- 但模型预测准确率未达预期

上述例子中，可能在某个学习率下已经收敛但未达预期，也可能出现了梯度爆炸或消失，所以这里可以尝试调整学习率

我们可以学习 pytorch 官方的 [如何调整学习率](https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate) 来动态调整学习率
