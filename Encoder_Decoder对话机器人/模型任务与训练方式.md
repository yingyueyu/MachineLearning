# 模型任务与训练方式

这里以 Encoder-Decoder 模型和 Decoder-Only 模型为例，介绍两者适应的任务

## Encoder-Decoder:
  
Encoder-Decoder，用于处理序列到序列任务 seq2seq

- 翻译任务: src 为元语句，tgt 为翻译后的语句；例如: src: 你好吗？ tgt: how are you?
- 对话任务: src 为对话发起人说的话，tgt 为应答方响应的回复；例如: src: how are you? tgt: i'm fine, thank you.

值得一提的是，Encoder-Decoder模型的训练流程和测试流程不同，以对话为例：

- 训练: src: `how are you ?`，此时目标序列为 tgt: `<sos> i am fine , thank you .`。src 和 tgt 都是完整的语句，真实标签 label: `i am fine , thank you . <eos>`
- 测试（推理）: src: `how are you ?`，此时目标序列初始为 tgt: `<sos>`，让模型预测一个结果，如: `i`，然后拼接到 tgt 后，得到下一轮的 tgt: `<sos> i` 然后再次输入 src 和 tgt，此时 tgt 长度为二，所以输出 tgt 为 `i am`，然后又将输出结果 `am` 拼接到 tgt 后: `<sos> i am`，继续预测下个字。这个过程直到输出长度达到上限或出现 `<eos>` 为止

## Decoder-Only

Decoder-Only 主要用于生成任务，简单理解就是一种**文本接龙**

以下描述中 input 代表模型输入，output 代表模型输出

### 生成任务

生成任务是: 给模型一个前置提示词，模型会续写生成后续内容

训练时通常以**完整的一句话**为输入

- input: `<sos> how are you ?`
- output: `how are you ? <eos>`

训练时：模型会将整个句子作为输入，然后学习预测每个 token 的下一个 token：

- "<sos>" -> "how",
- "how" -> "are",
- "are" -> "you",
- "you" -> "?",
- "?" -> "<eos>".

推理时：模型会根据前文提示词，进行**自回归**预测，例如:

- "how are" -> "you",
- "how are you" -> "?",
- "how are you ?" -> "<eos>"（生成结束）。

==**注意:** 推理时不需要用 `<sos>` 作为 input 的起始 token==

### 对话任务

对话任务可以在大规模预训练生成模型的基础上做微调，微调时的输入和输出中

**训练的例子：**

假设我们有如下的对话：

1. 用户：Hello, how are you?
2. 模型：I’m doing well, thank you.

这个对话的输入和输出可以按如下方式构建：

- **输入：**`<sos> User: Hello, how are you? <sep> Bot:`
  - 这里 <sos> 代表序列的开始，<sep> 是用于区分用户和模型发言的分隔符。
  - 模型需要根据用户提供的上下文生成下一句话。
- **输出：**`I’m doing well, thank you. <eos>`
  - 模型的任务是从输入中生成完整的输出回答。

在具体的训练过程中，模型学习逐步预测输出的每个 token。例如：

在看到 `"<sos> User: Hello, how are you? <sep> Bot:"` 时，模型首先预测 `"I"`;
之后，模型预测 `"’m"`，然后 `"doing"`, 依次生成后续的内容，直到 `<eos>`。

在对话任务时，我们需要添加角色，常用角色有: `user` `system` `assistant` `observertion`

**推理时的输入和输出：**

- **输入**：历史对话上下文，即用户的输入和模型之前的回复。
- **输出**：模型逐步生成的对话回应，直到生成 `<eos>`（或达到最大长度）。

**推理的例子：**

假设用户输入如下：

1. 用户：What’s your favorite color?

模型在推理时的流程如下：

- **输入：**`<sos> User: What’s your favorite color? <sep> Bot:`
  - 这里 `<sos>` 仍然标记序列的开始，`<sep>` 区分用户发言和模型回应。这个输入相当于上下文，提示模型生成对话的下一部分。
- **输出：**`My favorite color is blue. <eos>`
  - 模型基于输入逐步生成输出的 token，直到生成 `<eos>`，表示对话结束。